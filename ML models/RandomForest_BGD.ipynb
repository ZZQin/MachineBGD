{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23566 entries, 201140501469-2 to 203161000067-4\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Gender                      23566 non-null  int64  \n",
      " 1   Age                         23566 non-null  int64  \n",
      " 2   Cough                       23566 non-null  int64  \n",
      " 3   Fever                       23566 non-null  int64  \n",
      " 4   Active.Breathing.Shortness  23566 non-null  int64  \n",
      " 5   Weight.Loss                 23566 non-null  int64  \n",
      " 6   Haemoptysis                 23566 non-null  int64  \n",
      " 7   TB.Medication.History       23566 non-null  int64  \n",
      " 8   qXRv2                       23566 non-null  float64\n",
      " 9   CAD4TB6                     23566 non-null  int64  \n",
      " 10  JF1                         23566 non-null  float64\n",
      " 11  IF2                         23566 non-null  float64\n",
      " 12  Xpert2Outcome_num           23566 non-null  int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhizh\\.conda\\envs\\RecSys\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# Select features\n",
    "MDF = pd.read_csv('DataWrangling/ML.csv', index_col=0, na_values=[' ']).fillna(0)\n",
    "MDF.dtypes\n",
    "MDF['Gender'] = MDF['Gender'].replace({'F': 0, 'M': 1})\n",
    "MDF.head()\n",
    "\n",
    "## Convert 'Yes' to 1\n",
    "cols = ['Cough', 'Fever', 'Active.Breathing.Shortness', 'Weight.Loss', 'Haemoptysis', 'TB.Medication.History']\n",
    "MDF[cols] = MDF[cols].replace({'Yes':1, 'No': 0})\n",
    "\n",
    "MDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the MDF by up-sampling Minority Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19933\n",
       "1     3633\n",
       "Name: Xpert2Outcome_num, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDF.Xpert2Outcome_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19933\n",
       "0    19933\n",
       "Name: Xpert2Outcome_num, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "MDF_majority = MDF[MDF.Xpert2Outcome_num==0]\n",
    "MDF_minority = MDF[MDF.Xpert2Outcome_num==1]\n",
    " \n",
    "# Upsample minority class\n",
    "MDF_minority_upsampled = resample(MDF_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= 19933)    # to match majority class\n",
    "#                                  random_state=321)    # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "MDF_upsampled = pd.concat([MDF_majority, MDF_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "MDF_upsampled.Xpert2Outcome_num.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test & train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balanced MDF\n",
    "array = MDF_upsampled.values\n",
    "# array = MDF.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = array[:,[0,1,2,3,4,5,6, 7]] # take the first few columns as x to predict 'class'\n",
    "Y = array[:,11] # separate 'class' variable as the predictor\n",
    "\n",
    "# encode class values as integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "\n",
    "## Original MDF\n",
    "dfi = MDF.values\n",
    "# split into input (X) and output (Y) variables\n",
    "Xi = dfi[:,[0,1,2,4,5,6,7,8]].astype(float)\n",
    "Yi = dfi[:,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MDF_upsampled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, encoded_Y, test_size=0.20)\n",
    "# We set the random seed via the random_state argument to a fixed number to ensure that each algorithm is evaluated on the same splits of the training MDF.\n",
    "\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RFC100', RandomForestClassifier(n_estimators=100, random_state=42)))\n",
    "models.append(('RFC10_42', RandomForestClassifier(n_estimators=10, random_state=42)))\n",
    "\n",
    "# models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='roc_auc')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "    \n",
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, encoded_Y, test_size=0.20)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rfc.fit(X_train, Y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_train, Y_train, ax=ax, alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# print(rfc.feature_importances_)\n",
    "# print(rfc.predict(X_validation))\n",
    "\n",
    "# joblib.dump(rfc, 'Results/trained_RandomForest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the balanced MDF to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_validation, Y_validation, ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the original MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPred = rfc.predict_proba(Xi)[:,1]\n",
    "\n",
    "# print(allPred[:,0])\n",
    "MDF['IndividualRiskScore'] = pd.DataFrame(allPred, columns=['pred'])\n",
    "\n",
    "MDF.to_csv(r'Results\\pred_MDF.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the performance of  a Logistic Regression Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisualAssess import evalBinaryClassifier\n",
    "F1 = evalBinaryClassifier(rfc, X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm = confusion_matrix(Y_validation, X_validation[:, 2])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a Decision Tree from a Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT COMPLETE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Extract single tree\n",
    "estimator = rfc.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
