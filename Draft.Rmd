---
title: "Draft"
author: "Zhi Zhen Qin"
output: 
  word_document
    # reference_docx: C:/Users/zhizh/OneDrive - Stop TB Partnership/UNOPS/10 Paper Writing/CAR software/10 Manuscript/3 Nepal_Cameroon/Deep Learning CXR Compare - Submission SR_ZZ.docx

---

```{r Global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=15, fig.height=12, echo=FALSE, warning=FALSE, message=FALSE)
library(moments)
```
  
# Introduction
The improved theoretical understanding in AI technology, the ubiquity of large annotated datasets, and the advance in computer power have fostered a rapid expansion of the AI industry in medical diagnosis. Until recently, the most accurate AI methods for image analysis require feature manual segmentation of anatomic structures, detection or computation of specific features annotated by experts. The breakthrough in the ImageNet 2012 Challenges popularized the use of deep learning in neural networks to analyse medical images. Inspired by the human nervous system, neural networks are interconnected functions, each comprised of a weight and a bias coefficient. In deep learning, the networks are trained using large sets of known positive and negative data (ground truth) in multiple hidden layers. The networks “learn” by adjusting the weights and biases of the underlying functions based on the difference between predictions and ground, a process called back-propagation. The increased computational power makes it possible for a complex deep learning network to modify itself using a large training dataset so that the resulting trained algorithms can identify new and unseen data. 

These AI algorithms provide opportunities for new solutions to tackle tuberculosis (TB), a disease kills more people world-wide than any single infectious disease. Immediately identifying TB presumptives or patients is critical to prevent further spread of the infection. Chest x-ray is recommended by the World Health Organization (WHO) as a screening and triage test prior to the use of Xpert MTB/RIF. However, there is a lack of qualified radiologists who can quickly read CXR films in many high TB burden countries. Several AI companies have emerged in recent years promising to quickly screen digital chest-radiographs to identify people in need of further diagnostic testing for TB. 

However, like most AI algorithms, no one knows how exactly the resulting algorithms work, not even the engineers who developed them, earning AI the “black boxes” reputation. Companies are not eager to share how exactly they built their algorithms as this is extremely valuable and it is a fiercely guarded trade secret. Often the marketed accuracy is done on the same data superset for training, testing and validation and cannot be generalized to other setting. Current scientific evidence is limited and mostly available for one product, CAD4TB (Delft Imaging Systems, Netherlands). However, significant changes have been made to the latest version (v6) of CAD4TB and it has limited publication. There is only one peer-reviewed publication on the performance of other DL systems for detecting TB abnormalities with a relatively small dataset. WHO has not made a recommendation on the use of automated reading systems for TB due to the current lack of evidence [WHO]. In response to this, we evaluated multiple DL systems available for TB screening and triage using a large dataset unseen by any AI developers to help National TB Programmes, medical professionals and patients to assess the true diagnostics accuracy of these algorithms.


# Methods
In this retrospective study, we used data consecutively from all adults (> 15 years) presented any of the three TB Screening Centres (SCs), which were established by icddr,b with funding from the Stop TB Partnership's TB REACH Initiative, between 15 May 2014 and 4 October 2016. The three SCs cover a vast network of more than 2,000 private providers and 133 NTP facilities across Dhaka. After providing informed consent, each participant was verbally screened for symptoms and received a posterior-anterior CXR using digital X-ray machines (Delft EZ DR X-ray) and was asked to submit a sputum sample for a free Xpert test. Xpert test was performed again if the initial test failed (invalid, error, or no result). The final Xpert results were used as the bacteriological evidence and the reference standard in this evaluation. A group of 3 Bangladeshi, board-certified radiologists (all with MD/MBSS degree in radiology and X,Y,Z years of experience??) read all of the CXR images remotely. The radiologists were blinded to all testing and clinical (and demographic data?? icddr,b please confirm) data and provided standard radiology reports and graded each CXR as follows (criteria to be attached): a. Highly Suggestive: including highly suggestive of TB only, b. Possibly TB: including abnormality highly suggestive of TB and possibly associated with TB, c. Any Abnormality: including abnormality highly suggestive of TB, possibly associated with TB and non-TB abnormality, d. Normal. Anyone who was unable or unwilling to acquire a CXR was referred to a nearby public-sector health facility. 

Through the network and the database of innovators developed under the TB REACH initiatives and the Accelerator for Impact project at Stop TB Partnership, we identified and selected five DL systems, all have stable version control, to be included in this study: CAD4TB (v6), qXR (v2) developed by Qure.ai (India), Lunit INSIGHT for Chest Radiography (v4.7.2) developed by Lunit (South Korea), JF CXR-1 (v2) developed by JF Healthcare (China) and InferRead®DR (v2) by Infervision (China). The 5 DL systems scored the images remotely through Secured File Transfer Protocol from the Stop TB repository except for Delft, in which case the data was shared through cloud transfer. All machine reading was performed independently with the developers blinded to all testing, clinical and demographic data. All DL systems produce a continuous abnormality score (from 0 to 100 or from 0% to 100%) presenting the probability of presence of TB. We assess the 5 DL systems firstly by describing the distribution of AI scores disaggregated by Xpert status and by prior history of TB. Mann-Whitney U test was used to compared non-normal distribution. 

Instead of depending on the pre-defined threshold scored selected by some vendors, we choose the threshold cutoff to be comparative to the three categories used by the human readers (reading criteria described below). For example, for highly suggestive of TB, we chose the cutoff score to produce the same dichotomized screening decisions in terms of sensitivity and we compare the difference in specificity using McNemar test for paired proportions.
  
We evaluated and compared the overall performance of the 5 DL systems using threshold-free measurements. In additional to the area under receiver operating characteristic (ROC) curves (AUC), which shows the tradeoff between sensitivity and specificity with varying thresholds, we also calculated and compared the area under Precision-Recall (PRC) curve (PRAUC), which shows precision values for corresponding sensitivity values and is more informative than the ROC curve when evaluating binary classifier on imbalanced datasets. [Saito 2015]. We also plotted sensitivity, specificity, and PPV with varying AI scores to understand the influence of the selection of cutoff threshold scores on programmatic performance. We plotted the proportion of Xpert saved  against sensitivity to understand the sensitivity loss as further testing is triaged 

Furthermore, we divided the test set by patient age, prior TB history and referral types to evaluate the performance of the 5 DL systems in each subpopulation in terms of AUC and PRAUC.

## Ethics
All enrolled participants provided informed written consent. The study protocol was reviewed and approved by the Research Review Committee and the Ethical Review Committee at the International Centre for Diarrhoeal Disease Research, Bangladesh (icddr,b).

## Role of the AI Developers
The AI developers had no role in study design, data collection, analysis plan, or writing of the study. The developers only had access to the CXR images, and did not receive any of the demographic, symptom, medical, or testing data of the participants.


# Results

```{r Load, warning=FALSE, results='hide'}
source("Chapter/table1.R")
```
  
A total of 24,031 people were consecutively recruited from the three TB SCs. Excluding 17 individuals without a CXR and 107 individuals aged 15 or less, a total of `r sum(MDF$Age>=15)`  individuals were included in this analysis. The median age was `r T1$Overall[2]`, and `r paste0(substr(as.character(T1$Overall[[3]]), 13,16), "%")` were female, and almost all (`r paste0(substr(as.character(T1$Overall[[9]]), 8,11), "%")`) had at least one TB-related symptom. The most common symptoms are cough (`r paste0(substr(as.character(T1$Overall[[4]]), 8,11), "%")`), fever (`r paste0(substr(as.character(T1$Overall[[5]]), 8,11), "%")`), weight loss  (`r paste0(substr(as.character(T1$Overall[[7]]), 8,11), "%")`), and shorteness of breath (`r paste0(substr(as.character(T1$Overall[[6]]), 8,11), "%")`). Hemoptysis was only reported in `r paste0(substr(as.character(T1$Overall[[8]]), 8,11), "%")` participants. Noticeably, there were `r paste0(substr(as.character(T1$Overall[[10]]), 7,10), "%")` participants suspected of having TB already had prior TB history. The prevalence of bacteriologically-confirmed (Bac+) TB, confirmed by Xpert, in this population overall was `r paste0(substr(as.character(T1$Overall[[11]]), 7,10), "%")`. Among Bac+ individuals, `r percent(sum(MDF$RIF.Result %in% "Detected")/sum(MDF$Xpert2Outcome_num %in% "1"))` were resistant to rifampicin. The radiologists graded `r T1$Overall[25]` as Highly Suggestive, `r T1$Overall[26]` as Possibly TB, `r T1$Overall[27]` as Any Abnormality. The medians of the abnormality scores in Bac+ group were significantly different from those in the Xpert negative group were (Mann-Whitney U test <0.05) for all 5 DL systems. 


There are three sources of patients: the greatest proportion of test results came from people who were referred by either public sector or private sector health providers (n=`r T1$Overall[22]`);  `r T1$Overall[23]` individuals were tested in NTP DOTS facilities after an inital negative smear; and `r T1$Overall[24]` individuals walked-in / self-presented (Table 1). Across all referral groups,  `r T1$Overall[11]` MTB-positive TB patients were detected; the prevalence of Xpert positive TB was lowest among walk-ins: `r T1$WalkIn[11]`, highest in the NTP DOTS retested subgroup (`r T1[6, 11]`).   
  
### Histogram 
![](Results/density.tif){width=900px}

The stacked density plot in Fig-X shows the distributions of the 5 DL systems' scores disaggregated by Xpert outcomes and by prior TB history. The dark and light red bars were Bac negative and the dark and light green bars were Bac positive. An ideal test should have a density plot with all the red bars left skewed (positive skew) and all green bars right skewed with no overlap. Lunit's, qXR's and InferReadDR's density plot showed the dichomization pattern. Although almost all Bac positive patients received high abnormality scores (95-100) from JF CXR-1, so were many Bac negative patients, of which, mostly were healthy people but with a prior TB history (dark red), leading to excessive recall. When separately examine the distribution of the abnormality scores from the health people but with priro TB history, the distrbutions of all DL systems were right skewed, instead of left skewed (InferReadDR: `r round(skewness(MDF[MDF$Xpert2Outcome_num ==0 & MDF$TB.Medication.History %in% "Yes", 33]),3)`,  qXR: `r round(skewness(MDF[MDF$Xpert2Outcome_num ==0 & MDF$TB.Medication.History %in% "Yes", 28]),3)`, Lunit INSIGHT CXR: `r round(skewness(MDF[MDF$Xpert2Outcome_num ==0 & MDF$TB.Medication.History %in% "Yes", 29]),3)`, CAD4TB: `r round(skewness(MDF[MDF$Xpert2Outcome_num ==0 & MDF$TB.Medication.History %in% "Yes", 27]),3)`, and JF CXR-1: `r round(skewness(MDF[MDF$Xpert2Outcome_num ==0 & MDF$TB.Medication.History %in% "Yes", 30]),3)`), which we postulated resulted from issues in the algorithms' ability to differentiate between old scarrings and active lesions.

### Comparison of sensitivity and specificity between human reading and the predictions of the DL systems
```{r}
source("radiologist.R")
humanAI <- read.csv("Results/HumanAI.csv", )
knitr::kable(humanAI, row.names = F)
```

To compare the DL systems withthe group of Bangladeshi radiologists, we choose thresholds to match the sensitivity of each grading made by the human readers. The grading of "highly suggestive of TB" had a low sensitivity of `r paste0(percent(Radiologist$Sens[1]), " (95%CI: ", percent(Radiologist$Sens_L[1]), " - ", percent(Radiologist$Sens_H[1]),")")` but a high specificity of `r paste0(percent(Radiologist$Spec[1]), " (95%CI: ", percent(Radiologist$Spec_L[1]), " - ", percent(Radiologist$Spec_H[1]),")")`. All 5 DL systems demonstrated statistically significant improvement in specificity. The increases in specificities range from 1.48% (CAD4TB) to 8.96% (Lunit INSIGHT CXR).     

If radiologists' rading of "Possibly TB" had been used to triage the follow-on Xpert testing, the resulting sensitivity would be `r paste0(percent(Radiologist$Sens[2]), " (95%CI: ", percent(Radiologist$Sens_L[2]), " - ", percent(Radiologist$Sens_H[2]), ")")` and the specificity would be `r paste0(percent(Radiologist$Spec[2]), " (95%CI: ", percent(Radiologist$Spec_L[2]), " - ", percent(Radiologist$Spec_H[2]), ")")`. The matching AI classificiation by the 5 DL systems continued showing statistical improvement in specificty. The increases in specificities range from 1.34% (JF CXR-1) to 7.62% (Lunit INSIGHT CXR). 

The grading of "any abnormality" has high sensitivity, `r paste0(percent(Radiologist$Sens[3]), " (95%CI: ", percent(Radiologist$Sens_L[3]), " - ", percent(Radiologist$Sens_H[3]), ")")`, but a reduced specificity, `r paste0(percent(Radiologist$Spec[3]), " (95%CI: ", percent(Radiologist$Spec_L[3]), " - ", percent(Radiologist$Spec_H[3]), ")")`. The matching AI classification statistically outperform in terms of specificity. qXR gained the highest in specificity (`r paste0(humanAI$Diff.specificity[12], " (95%CI: ", humanAI$CI[12], ")")`).  


###  Overall performance of 5 DL products 

![](Results/Figure-2 ROCs.tif){width=900px}
We summarized the ROC curves by computing the area under the curve (AUC). 

The area under the curve (AUC) for all referral groups is 0.74 (95% CI: 0.73-0.75). The CAD4TB software performed significantly better among walk-ins (AUC 0.84, 95% CI: 0.81-0.87) compared to people referred from NTP facilities (AUC 0.77, 95% CI: 0.74-0.79) and private providers (AUC 0.72, 95% CI: 0.70-0.73).

To rule out normal cases with high confidence, we used a very-low decision threshold. For the UK data, we achieved a negative predictive value (NPV) of 99.99% while retaining a specificity of 41.15%. 
  

###  Threthold Selection

![](Results/4 Curves.tif){width=900px}
  
To rule out normal cases with high confidence, we used a very-low decision threshold. For the UK data, we achieved a negative predictive value (NPV) of 99.99% while retaining a specificity of 41.15%. 

### Results across age and prior TB history


![](Results/AUC plot.tif){width=900px}

We compared that the performance of 5 DL systems varies across age groups. We also find that all DL systems perform worse on XXX than on, which is consistent with the decreased sensitivity of radiologists for patients... Differences in the model’s performance in benign/not benign classification is larger than in malignant/not malignant classification. We hypothesize that this is due to age and prior TB hisotry there are more abnormality on the chest or old scaring influenced the detection of active TB. 

# Discussion

The study show that the 5 DL prdocuts had clinical potential. The classificaitions made by the DL system coul be used to when skilled radiologists are scare in high TB burden countries which improve the standard of care. The AI system could also be used to provide automated, immediate feedback in the screening setting.
  
