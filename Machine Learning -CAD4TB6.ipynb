{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23566 entries, F to M\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         23566 non-null  int64  \n",
      " 1   Cough                       23566 non-null  object \n",
      " 2   Fever                       23566 non-null  object \n",
      " 3   Active.Breathing.Shortness  23566 non-null  object \n",
      " 4   Weight.Loss                 23566 non-null  object \n",
      " 5   Haemoptysis                 23566 non-null  object \n",
      " 6   TB.Medication.History       23566 non-null  object \n",
      " 7   qXRv2                       23566 non-null  float64\n",
      " 8   CAD4TB6                     23566 non-null  int64  \n",
      " 9   JF1                         23566 non-null  float64\n",
      " 10  IF2                         23566 non-null  float64\n",
      " 11  Xpert2Outcome_num           23566 non-null  int64  \n",
      "dtypes: float64(3), int64(3), object(6)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Active.Breathing.Shortness</th>\n",
       "      <th>Weight.Loss</th>\n",
       "      <th>Haemoptysis</th>\n",
       "      <th>TB.Medication.History</th>\n",
       "      <th>qXRv2</th>\n",
       "      <th>CAD4TB6</th>\n",
       "      <th>JF1</th>\n",
       "      <th>IF2</th>\n",
       "      <th>Xpert2Outcome_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.589495</td>\n",
       "      <td>70</td>\n",
       "      <td>0.90624</td>\n",
       "      <td>0.295180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>30</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.630787</td>\n",
       "      <td>51</td>\n",
       "      <td>0.99537</td>\n",
       "      <td>0.700530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>29</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00915</td>\n",
       "      <td>0.072238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>31</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>30</td>\n",
       "      <td>0.29928</td>\n",
       "      <td>0.219891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.368823</td>\n",
       "      <td>59</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.758563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Cough Fever Active.Breathing.Shortness Weight.Loss Haemoptysis  \\\n",
       "Gender                                                                       \n",
       "F        22   Yes   Yes                         No         Yes          No   \n",
       "M        30   Yes   Yes                         No          No          No   \n",
       "M        29   Yes    No                        Yes          No          No   \n",
       "F        31   Yes   Yes                        Yes          No          No   \n",
       "F        32    No    No                         No         Yes          No   \n",
       "\n",
       "       TB.Medication.History     qXRv2  CAD4TB6      JF1       IF2  \\\n",
       "Gender                                                               \n",
       "F                         No  0.589495       70  0.90624  0.295180   \n",
       "M                         No  0.630787       51  0.99537  0.700530   \n",
       "M                         No  0.074441        3  0.00915  0.072238   \n",
       "F                         No  0.051884       30  0.29928  0.219891   \n",
       "F                         No  0.368823       59  0.99778  0.758563   \n",
       "\n",
       "       Xpert2Outcome_num  \n",
       "Gender                    \n",
       "F                      1  \n",
       "M                      0  \n",
       "M                      0  \n",
       "F                      0  \n",
       "F                      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('DataWrangling/ML.csv', index_col=0, na_values=[' ']).fillna(0)\n",
    "\n",
    "dataset.info()\n",
    "\n",
    "dataset['Xpert2Outcome_num'] = dataset['Xpert2Outcome_num'].astype('str')\n",
    "dataset.dtypes\n",
    "# dataset['Xpert2Outcome_num'] = dataset['Xpert2Outcome_num'].replace({'0': 'Neg', '1': 'Pos'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to convert \"Yes\" to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 1], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Cough', 'Fever', 'Active.Breathing.Shortness', 'Weight.Loss', 'Haemoptysis', 'TB.Medication.History']\n",
    "dataset[cols] = dataset[cols].replace({'Yes':1, 'No': 0})\n",
    "\n",
    "array = dataset.values\n",
    "array[1, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and set out the model\n",
    "\n",
    "We set the random seed via the random_state argument to a fixed number to ensure that each algorithm is evaluated on the same splits of the training dataset. The specific random seed does not matter. \n",
    "\n",
    "We are using the metric of ‘accuracy‘ to evaluate models.\n",
    "\n",
    "This is a ratio of the number of correctly predicted instances divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate). We will be using the scoring variable when we run build and evaluate each model next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,[0,1,2,3,4,5,6, 8]] # take the first few columns as x to predict 'class'\n",
    "y = array[:,11] # separate 'class' variable as the predictor\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "# We set the random seed via the random_state argument to a fixed number to ensure that each algorithm is evaluated on the same splits of the training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 1 1 ... 0 0 70]\n",
      " [30 1 1 ... 0 0 51]\n",
      " [29 1 0 ... 0 0 3]\n",
      " ...\n",
      " [35 1 1 ... 0 0 66]\n",
      " [33 1 1 ... 0 0 62]\n",
      " [29 1 1 ... 0 0 85]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models\n",
    "Let’s test 6 different algorithms:\n",
    "\n",
    "Logistic Regression (LR)\n",
    "Linear Discriminant Analysis (LDA)\n",
    "K-Nearest Neighbors (KNN).\n",
    "Classification and Regression Trees (CART).\n",
    "Gaussian Naive Bayes (NB).\n",
    "Support Vector Machines (SVM).\n",
    "\n",
    "This is a good mixture of simple linear (LR and LDA), nonlinear (KNN, CART, NB and SVM) algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "We now have 6 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a plot of the model evaluation results and compare the spread and the mean accuracy of each model. There is a population of accuracy measures for each algorithm because each algorithm was evaluated 10 times (via 10 fold-cross validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()\n",
    "\n",
    "# # Find the error rate on the traininign set\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# mse = mean_absolute_error(Y_train, model.predict(X_train))\n",
    "# print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "Now we want to get an idea of the accuracy of the model on our validation set.\n",
    "\n",
    "This will give us an independent final check on the accuracy of the best model. It is valuable to keep a validation set just in case you made a slip during training, such as overfitting to the training set or a data leak. Both of these issues will result in an overly optimistic result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(gamma='auto')\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predictions\n",
    "\n",
    "The confusion matrix provides an indication of the three errors made.\n",
    "\n",
    "The classification report provides a breakdown of each class by precision, recall, f1-score and support showing excellent results (granted the validation dataset was small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mse = mean_absolute_error(Y_validation, model.predict(X_validation))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump / Save the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model, 'Results/trained_ML_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# These are the feature labels from our data set\n",
    "feature_labels = np.array(['Gender', 'Age', 'Cough', 'Fever', 'Active.Breathing.Shortness', 'Weight.Loss', 'Haemoptysis', 'TB.Medication.History', 'CAD4TB'])\n",
    "\n",
    "# Load the trained model created with train_model.py\n",
    "model = joblib.load('Results/trained_ML_model.pkl')\n",
    "\n",
    "\n",
    "# # Create a numpy array based on the model's feature importances\n",
    "coefficients = model.coef_[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each feature label, from most important to least important (reverse order)\n",
    "# for index in coefficients:\n",
    "#     print(\"{} - {}\".format(feature_labels[index], coefficients[index]))\n",
    "print(feature_labels)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "testX = array[:,[0,1,2,3,4,5,6, 8]] # take the first 4 columns as x to predict 'class'\n",
    "testy = array[:,11] # separate 'class' variable as the predictor\n",
    "\n",
    "# generate a original qXR score prediction (majority class)\n",
    "ns_probs = array[:,8]\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('Original AI score ONLY: ROC AUC=%.5f' % (ns_auc))\n",
    "print('Combined: ROC AUC=%.5f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Original AI score ONLY')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Combined')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
